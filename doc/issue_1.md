# Issue #1 â€“ Automatic Metaâ€‘Tag Generation in Colab

**URL:** https://github.com/bonsai/fotei/issues/1

## ğŸ“– Overview
The issue proposes adding **automatic semantic tag generation** for images and videos in the FOTEI pipeline, using Googleâ€¯Colab and a largeâ€‘languageâ€‘model API (Geminiâ€¯1.5â€¯Flash).  Tags will be stored as JSON (and optionally embedded in EXIF) and later used for search and organization.

## ğŸ¯ Goal
Create a robust, batchâ€‘capable tagging system that runs on Colab, integrates with the existing pipeline, and provides a searchable tag database.

## ğŸ—‚ï¸ Proposed Implementation Plan (as captured from the issue)

### Phaseâ€¯1 â€“ Gemini API Integration & Core Service
1. **Gemini API client** â€“ install `googleâ€‘generativeai`, read `GEMINI_API_KEY` from the environment.
2. **`generate_semantic_tags` function** â€“ send an image/video (or thumbnail) to Gemini, receive a commaâ€‘separated list of Japanese tags, and return a cleaned `List[str]`.
3. **JSON storage** â€“ write tags to `semantic_tags_metadata.json` alongside the media on Googleâ€¯Drive.

### Phaseâ€¯2 â€“ Batch Processing & Colab Optimisation
1. **Batch driver** (`batch_tagging.py`) â€“ walk a root folder, call the Phaseâ€‘1 function, skip alreadyâ€‘tagged files, and write a checkpoint after each directory.
2. **Resumability** â€“ checkpoint file (`.fotei_tag_checkpoint`) allows the job to continue after a timeout.
3. **T4 optimisation** â€“ monitor GPU memory, use exponential backâ€‘off, and keep the job within Colab limits.

### Phaseâ€¯3 â€“ Semantic Search & Pipeline Integration
1. **Search utility** â€“ `search_by_tags(tags, root_dir)` loads the JSON metadata and returns matching file paths.
2. **Integration** â€“ modify existing scripts (e.g., `10_semantic_ai_processor.py`) to filter media by tags before uploading or archiving.
3. **Optional EXIF embedding** â€“ write tags back into image metadata for offline use.

## ğŸ“¦ Deliverables
| Phase | Artifact |
|------|----------|
| 1 | `src/semantic_tagging.py` â€“ Gemini wrapper.
| 2 | `src/batch_tagging.py` â€“ batch driver, checkpointing.
| 3 | `src/search_tags.py` (to be added) + updated pipeline scripts.
| Documentation | Updated `doc/README.md` with usage examples and CI instructions.

## ğŸ› ï¸ Current Repository State
- The project has been reorganised into `src/`, `doc/`, and `dev/`.
- The Geminiâ€‘based tagging module (`semantic_tagging.py`) and batch driver (`batch_tagging.py`) have been added and committed on the `feature/colab-integration` branch.
- CI workflow (`.github/workflows/ci.yml`) is in place to lint, typeâ€‘check, and test the code.

## âœ… Next Steps for You
1. **Add unit tests** for `generate_semantic_tags` (mock the Gemini client) and for the batch driver.
2. **Create `src/search_tags.py`** implementing the search utility.
3. **Update documentation** (`doc/README.md`) with quickâ€‘start instructions for Colab users.
4. **Push any further changes**; CI will automatically validate them.

---
*Generated from the GitHub issue discussion and the â€œCoding Planâ€ comment.*
## ğŸ—‚ï¸ Broken Task TODO List (Stepâ€‘byâ€‘Step)
- [ ] **Phaseâ€¯1 â€“ Gemini API Integration**
  - [ ] Install `google-generativeai` and set `GEMINI_API_KEY` in Colab.
  - [ ] Verify `generate_semantic_tags` implementation (already added).
  - [ ] Write unit test mocking Gemini client.
  - [ ] Add JSON storage logic and ensure file is written to Drive.
- [ ] **Phaseâ€¯2 â€“ Batch Processing**
  - [ ] Review `batch_tagging.py` for checkpoint handling.
  - [ ] Add progress bar and error handling for failed files.
  - [ ] Test resumability by interrupting the Colab run.
- [ ] **Phaseâ€¯3 â€“ Semantic Search**
  - [ ] Create `src/search_tags.py` with `search_by_tags` function.
  - [ ] Integrate search into `10_semantic_ai_processor.py`.
  - [ ] Add optional EXIF tag embedding.
- [ ] **Documentation & CI**
  - [ ] Update `doc/README.md` with usage examples.
  - [ ] Ensure CI runs tests for new modules.
  - [ ] Add a badge for CI status in the main README.
- [ ] **Final Review**
  - [ ] Verify all scripts run endâ€‘toâ€‘end in a Colab notebook.
  - [ ] Open a PR and request CodeRabbit review.
